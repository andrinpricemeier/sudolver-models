{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from PIL import Image\n",
    "from ImageAnalysis import ImageAnalysis\n",
    "from ImageTableExtraction import ImageTableExtraction\n",
    "from SudokuDetection import SudokuDetection\n",
    "from solvers.sudoku.sudoku_solver import SudokuSolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.dpi']= 200\n",
    "plt.rcParams['figure.figsize'] = [5,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../data/original/\"\n",
    "annotated_folder = \"../data/training_data/\"\n",
    "testdata_folder = \"../data/testdata_dont_touch/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_samples(folder):\n",
    "    samples = []\n",
    "    for file in os.listdir(data_folder):\n",
    "         filename = os.fsdecode(file)\n",
    "         if filename.endswith(\".jpg\"):\n",
    "            fullname = data_folder + file\n",
    "            fullname_no_extension = data_folder + Path(fullname).stem\n",
    "            outcome = pd.read_json(fullname_no_extension + \".json\")\n",
    "            samples.append((filename, outcome))\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_samples(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(samples):\n",
    "    success = [x for x in samples if len(x[1][\"solution\"]) > 0]\n",
    "    print(len(success))\n",
    "    print(len(samples))\n",
    "    return len(success) / len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2903225806451613"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(samples, samples, test_size=0.20, random_state=42)\n",
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_annotated_files(samples, source_folder, destination_folder):\n",
    "    for test_sample in X_test:\n",
    "        image_filepath = test_sample[0]\n",
    "        image_fullpath = source_folder + image_filepath\n",
    "        image_target = destination_folder + image_filepath\n",
    "        name_no_ext = Path(image_filepath).stem\n",
    "        annotation_filepath = name_no_ext + \".xml\"\n",
    "        annotation_fullpath = source_folder + annotation_filepath\n",
    "        annotation_target = destination_folder + annotation_filepath\n",
    "        filename = os.fsdecode(image_filepath)\n",
    "        os.rename(image_fullpath, image_target)\n",
    "        os.rename(annotation_fullpath, annotation_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SudolverModel():\n",
    "    def __init__(self):\n",
    "        self.extractor = None\n",
    "        self.persp_transform = False\n",
    "        self.filters = []\n",
    "        self.solver = SudokuSolver()\n",
    "        self.detector = SudokuDetection(ImageAnalysis(), ImageTableExtraction())\n",
    "        \n",
    "    def predict(self, image_rgb):\n",
    "        try:\n",
    "            result = image_rgb\n",
    "            if self.extractor is not None:\n",
    "                preprocessed = self.extractor.preprocess(result)\n",
    "                result = self.extractor.predict(preprocessed, self.persp_transform)\n",
    "                if result is None:\n",
    "                    print(\"YOLO detected not sudoku\")\n",
    "                    return 0\n",
    "            for f in self.filters:\n",
    "                result = f.apply_filter(result)\n",
    "            return self.scan_and_solve(result)\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            return 0\n",
    "    \n",
    "    def get_params(self):\n",
    "        desc = \"\"\n",
    "        if self.extractor is not None:\n",
    "            desc += \"Extractor.Activated,\"\n",
    "        if self.persp_transform:\n",
    "            desc += \"PerspTransform.Activated\"\n",
    "        for f in self.filters:\n",
    "            desc += f.get_params() + \",\"\n",
    "        return desc\n",
    "    \n",
    "    def enable_extractor(self):\n",
    "        self.extractor = SudokuExtractor()\n",
    "        \n",
    "    def use_perspective_transform(self):\n",
    "        self.persp_transform = True\n",
    "    \n",
    "    def add_filter(self, new_filter):\n",
    "        self.filters.append(new_filter)\n",
    "    \n",
    "    def scan_and_solve(self, image_rgb):\n",
    "        result = None\n",
    "        try:\n",
    "            success, encoded_image = cv2.imencode('.jpg', image_rgb)\n",
    "            content = encoded_image.tobytes()\n",
    "            success, result = self.detector.detect(content)\n",
    "            if success:\n",
    "                solution = self.solver.solve(result)\n",
    "                return 1\n",
    "            else:\n",
    "                print(result)\n",
    "                return 0\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            if result is not None:\n",
    "                print(result)\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def eval_all(samples):\n",
    "    extractor = SudokuExtractor()\n",
    "    sharp_variants = (UnsharpMasking(10), Laplacian(10), UnsharpMasking(5), Laplacian(5), None)\n",
    "    results = []\n",
    "    total = len(samples)\n",
    "    for sharp in sharp_variants:\n",
    "            sudolver = SudolverModel()\n",
    "            sudolver.enable_extractor()\n",
    "            if sharp is not None:\n",
    "                sudolver.add_filter(sharp)\n",
    "            model_total = 0\n",
    "            for sample in tqdm(samples):\n",
    "                filename = sample[0]\n",
    "                image = cv2.imread(data_folder + filename)\n",
    "                image_rgb = to_rgb_from_bgr(image)\n",
    "                success = sudolver.predict(image_rgb)\n",
    "                model_total += success\n",
    "            model_desc = sudolver.get_params()\n",
    "            eval_result = (model_desc, model_total / total)\n",
    "            print(eval_result)\n",
    "            results.append(eval_result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(filepath):\n",
    "    return cv2.imread(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_rgb_from_bgr(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bgr_from_rgb(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_grayscale_from_bgr(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eq_hist_from_bgr(image):\n",
    "    return cv2.equalizeHist(to_grayscale_from_bgr(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsharp_masking(image, k=10):\n",
    "    normalized = image / 255.0\n",
    "    blurred = cv2.GaussianBlur(normalized, [5, 5], 3, 3)\n",
    "    mask = normalized - blurred\n",
    "    sharp = normalized + k*mask\n",
    "    sharp[sharp > 1] = 1\n",
    "    sharp[sharp < 0] = 0\n",
    "    sharp = sharp * 255\n",
    "    sharp = sharp.astype(np.uint8)\n",
    "    return sharp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian(image, alpha=10):\n",
    "    normalized = image / 255.0\n",
    "    laplacian = cv2.Laplacian(normalized, cv2.CV_64F)\n",
    "    sharp = normalized - alpha * laplacian\n",
    "    sharp[sharp > 1] = 1\n",
    "    sharp[sharp < 0] = 0\n",
    "    sharp = sharp * 255\n",
    "    sharp = sharp.astype(np.uint8)\n",
    "    return sharp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_higher_dpi(source_filepath, target_filepath, new_dpi=150):\n",
    "    im = Image.open(source_filepath)\n",
    "    im.save(target_filepath, dpi=(new_dpi,new_dpi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective_transform(image, conjugates, output_size=512):\n",
    "    output = np.float32([[0, 0], [output_size - 1, 0], [output_size - 1, output_size - 1], [0, output_size - 1]])\n",
    "    matrix = cv2.getPerspectiveTransform(conjugates, output)\n",
    "    return cv2.warpPerspective(image, matrix, (output_size, output_size), cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = annotated_folder + X_train[34][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = read_image(filepath)\n",
    "#plt.imshow(to_rgb_from_bgr(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(perspective_transform(image, np.float32([[75,150], [418,59], [442,443], [29,438]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(to_grayscale_from_bgr(image), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(eq_hist_from_bgr(image), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharp = unsharp_masking(image, k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharp = laplacian(image, alpha=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imgaug.augmenters.meta import Sequential\n",
    "import imgaug.augmenters as iaa\n",
    "import imageio\n",
    "import torch\n",
    "\n",
    "class SudokuExtractor():\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        self.model = torch.hub.load('C:/Projects/sudolver-models/data/model/yolov5', 'custom', path='C:/Projects/sudolver-models/data/trained_model/best_2022-04-09.pt', source='local') \n",
    "\n",
    "    def preprocess(self, image):\n",
    "        aug = [iaa.CenterPadToSquare(), iaa.Resize({\"height\": 640, \"width\": 640})]\n",
    "        seq = iaa.Sequential(aug)\n",
    "        return seq(image=image)\n",
    "        \n",
    "    def predict(self, image, persp_transform):\n",
    "        result = self.model(image)\n",
    "        if len(result) > 0:\n",
    "            pred = result.pandas()\n",
    "            xmin, ymin, xmax, ymax = (int(pred.xyxy[0]['xmin'].values[0]), int(pred.xyxy[0]['ymin'].values[0]), int(pred.xyxy[0]['xmax'].values[0]), int(pred.xyxy[0]['ymax'].values[0]))\n",
    "            if persp_transform:\n",
    "                return to_rgb_from_bgr(perspective_transform(image, self.pred_to_conjugates(xmin, ymin, xmax, ymax)))\n",
    "            else:\n",
    "                img = image[ymin:ymax+1, xmin:xmax+1]\n",
    "                cv2.imwrite(\"C:\\Projects\\sudolver-models\\data\\detected\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def pred_to_conjugates(self, xmin, ymin, xmax, ymax):\n",
    "        return np.float32([[xmin, ymin], [xmax, ymin], [xmax, ymax], [xmin, ymax]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFilter():\n",
    "    def apply_filter(self, image):\n",
    "        pass\n",
    "    \n",
    "    def get_params(self):\n",
    "        pass\n",
    "    \n",
    "class UnsharpMasking(ImageFilter):\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "        \n",
    "    def apply_filter(self, image_rgb):\n",
    "        return unsharp_masking(image_rgb, self.k)\n",
    "    \n",
    "    def get_params(self):\n",
    "        return f\"UnsharpMasking (k={self.k})\"\n",
    "    \n",
    "class Laplacian(ImageFilter):\n",
    "    def __init__(self, alpha=5):\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def apply_filter(self, image_rgb):\n",
    "        return laplacian(image_rgb, self.alpha)\n",
    "    \n",
    "    def get_params(self):\n",
    "        return f\"Laplacian (alpha={self.alpha})\"\n",
    "    \n",
    "class HigherDPI(ImageFilter):\n",
    "    def __init__(self, dpi=150):\n",
    "        self.dpi = dpi\n",
    "        \n",
    "    def apply_filter(self, image_rgb):\n",
    "        im = Image.fromarray(image_rgb)\n",
    "        temp_filename = \"C:/Projects/sudolver-models/data/high_dpi/temp.jpg\"\n",
    "        im.save(temp_filename, dpi=(self.dpi, self.dpi))\n",
    "        return to_rgb_from_bgr(read_image(temp_filename))\n",
    "    \n",
    "    def get_params(self):\n",
    "        return f\"Higher DPI = {self.dpi}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = eval_all(X_train)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
